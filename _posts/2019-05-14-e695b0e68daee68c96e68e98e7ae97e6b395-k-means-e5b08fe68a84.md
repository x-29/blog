---
ID: 239
post_title: 数据挖掘算法 K-Means 小抄
author: hemi
post_excerpt: ""
layout: post
permalink: http://hemi.im/archives/239
published: true
post_date: 2019-05-14 21:08:04
---
<!-- wp:paragraph -->
<p>分类要求样本数据必须事先已经归类。可以是人研究数据，手动打标签；但是在处理海量数据的时候，人工手动打标签代价太大，甚至是不可能完成得了的，这时就需要用聚类算法了。</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>聚类是一种把数据集划分成多个组或簇的过程，使得簇内的数据相似性很高，但与其他簇的数据相似性就很低。聚类分析是一种无监督学习方法，其目标就是通过对无标记训练样本的学习来揭露数据的内在性质以及规律。</p>
<!-- /wp:paragraph -->

<!-- wp:heading {"level":3} -->
<h3>K-means 算法</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>K-means 是一种简单的迭代型聚类算法，采用距离作为度量数据相似性的指标，从而发现给定数据集中的 K 个类，且每个类的中心是根据类中所有值的均值得到，每个类用聚类中心来描述。</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>K-means 算法的计算过程非常直观：</p>
<!-- /wp:paragraph -->

<!-- wp:image -->
<figure class="wp-block-image"><img src="https://i.loli.net/2019/05/14/5cdabc403872451498.png" alt=""/></figure>
<!-- /wp:image -->

<!-- wp:list {"ordered":true} -->
<ol><li>从数据集中随机选取 K 个元素，作为 k 个簇各自的初始中心点。比如上图中 K = 2。</li><li>分别计算剩下的元素到这 k 个中心点的距离，将这些元素分别划归到距离最近的簇。在图中，可以看到 A、B 属于上方的簇，C、D、E 属于下方的簇。</li><li>根据聚类结果，重新计算 k 个簇各自的中心点，计算方法是取簇中所有元素各自的坐标求平均值。</li><li>重复 2 至 3 步，直到每个簇的中心点不再发生变化。这时，就输出结果。距离每个中心点最近的数据聚类为同簇。</li></ol>
<!-- /wp:list -->

<!-- wp:heading {"level":3} -->
<h3>示例</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>以西瓜数据集 4.0 为例。为叙述方便，将编号为​ i 的样本称为 ​xi，这是一个包含 "密度" 和 "含糖率" 两个属性值的二维向量。</p>
<!-- /wp:paragraph -->

<!-- wp:table -->
<table class="wp-block-table"><thead><tr><th>编号</th><th>密度</th><th>含糖率</th><th>编号</th><th>密度</th><th>含糖率</th><th>编号</th><th>密度</th><th>含糖率</th></tr></thead><tbody><tr><td>1</td><td>0.697</td><td>0.460</td><td>11</td><td>0.245</td><td>0.057</td><td>21</td><td>0.748</td><td>0.232</td></tr><tr><td>2</td><td>0.774</td><td>0.376</td><td>12</td><td>0.343</td><td>0.099</td><td>22</td><td>0.714</td><td>0.346</td></tr><tr><td>3</td><td>0.634</td><td>0.264</td><td>13</td><td>0.639</td><td>0.161</td><td>23</td><td>0.483</td><td>0.312</td></tr><tr><td>4</td><td>0.608</td><td>0.318</td><td>14</td><td>0.657</td><td>0.198</td><td>24</td><td>0.478</td><td>0.437</td></tr><tr><td>5</td><td>0.556</td><td>0.215</td><td>15</td><td>0.360</td><td>0.370</td><td>25</td><td>0.525</td><td>0.369</td></tr><tr><td>6</td><td>0.403</td><td>0.237</td><td>16</td><td>0.593</td><td>0.042</td><td>26</td><td>0.751</td><td>0.489</td></tr><tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><td>10</td><td>0.243</td><td>0.267</td><td>20</td><td>0.282</td><td>0.257</td><td>30</td><td>0.446</td><td>0.459</td></tr></tbody></table>
<!-- /wp:table -->

<!-- wp:paragraph -->
<p>假定 K=3，随机选取三个样本 x6，x12，x27​ 作为初始中心点，即</p>
<!-- /wp:paragraph -->

<!-- wp:image -->
<figure class="wp-block-image"><img src="https://www.zhihu.com/equation?tex=\mu_1=(0.403;0.237)%EF%BC%8C\mu_2=(0.343;0.099%EF%BC%8C\mu_3=(0.532;0.476))" alt=""/></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>计算样本 ；​，它与中心点 ，，​ 的距离分别为 0.369，0.506，0.166。它与 ​ 的距离最近，因此 ​ 将被划入到 ​。类似地，计算数据集中的所有样本，得到簇的划分为：</p>
<!-- /wp:paragraph -->

<!-- wp:shortcode -->
$latex C_1=\{x_5,x_6,x_7,x_8,x_9,x_{10},x_{13},x_{14},x_{15},x_{17},x_{18},x_{19},x_{20},x_{23}\} $
<!-- /wp:shortcode -->

<!-- wp:shortcode -->
$latex C_2=\{x_{11},x_{12},x_{16}\} $
<!-- /wp:shortcode -->

<!-- wp:shortcode -->
$latex C_3={x_1,x_2,x_3,x_4,x_{21},x_{22},x_{24},x_{25},x_{26},x_{27},x_{28},x_{29},x_{30}} $
<!-- /wp:shortcode -->

<!-- wp:paragraph -->
<p>根据划分结果，计算各簇中所有元素的平均值分别得出新的中心点</p>
<!-- /wp:paragraph -->

<!-- wp:shortcode -->
$latex \mu^\prime_1=(0.473;0.214)，\mu^\prime_2=(0.394;0.066)，\mu^\prime_3=(0.623;0.388)$
<!-- /wp:shortcode -->

<!-- wp:paragraph -->
<p>重复上述过程，直到中心点不再变化。</p>
<!-- /wp:paragraph -->

<!-- wp:image -->
<figure class="wp-block-image"><img src="https://i.loli.net/2019/05/14/5cdabc4065e2825404.png" alt=""/></figure>
<!-- /wp:image -->

<!-- wp:paragraph -->
<p>第五轮迭代产生的结果与第四轮迭代相同，于是计算停止，得到最终的簇划分。</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->