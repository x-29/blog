---
title: "深入理解计算机系统(csapp)笔记-虚拟内存"
description: "这是深入理解计算机系统(Computer Systems A Programmer's Perspective 3rd)第六章的学习笔记."
date: 2022-05-19T21:02:10+08:10
draft: false
math: true
categories:
  - 读书笔记
tags:
  - cs
---

现代系统提供了一种对主存的抽象概念，叫做「虚拟内存（VM）」。虚拟内存提供了三个重要的能力：
- 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，这相当于在主存中的是活动区域，然后根据需要从磁盘读取数据到主存或将主存数据写回到磁盘。
- 它为每个进程提供了一致的地址空间。
- 它保护了每个进程的地址空间不被其他进程破坏。

## 物理和虚拟寻址

计算机系统的主存被组织成一个 $M$ 个连续的字节大小的单元组成的数组。每个字节都有一个唯一的「物理地址（Physical Address，PA）。第一个字节的地址为 0，接下来的字节地址为 1，再下一个为 2，依次类推。


CPU 使用物理地址访问内存的方式称为物理寻址（physical addressing），这种寻址方式通常在单进程的简单系统中使用。比如，嵌入式微控制器、数字信号处理器。

{{<figure width="500" src="/images/physical-addressing.jpg" caption="物理寻址">}}

然而，**现代处理器使用「虚拟寻址（virtual addressing）」方式**。

{{<figure width="600" src="/images/virtual-addressing.jpg" caption="虚拟寻址">}}

使用虚拟寻址，CPU 通过生成一个「虚拟地址（Virtual Address，VA）」来访问主存。这个虚拟地址在被送到主存之前先要经过「地址翻译（address translation）」转换成物理地址。地址翻译需要 CPU 硬件和操作系统相互配合，CPU 芯片上叫做「内存管理单元（Memory Management Unit，MMU）」的专用硬件，利用存放在主存中的查询表（页表）来动态翻译虚拟地址，查询表的内容由操作系统维护。

## 地址空间

地址空间（address space）是一个非负整数地址的有序集合。

在一个带有虚拟内存的系统中，CPU 从一个有 $N=2^n$ 个地址的地址空间中生成虚拟地址，这个地址空间称为「虚拟地址空间（virtual address space)」。一个地址空间的大小是由表示最大地址所需要的「位」数来描述的。例如，一个包含 $N=2^n$ 个地址的虚拟地址空间就叫做一个 $n$ 位地址空间。现代系统通常支持 32 位或者 64 位虚拟地址空间。

## 虚拟内存

概念上而言，将虚拟内存视为存储在磁盘上的 $N=2^n$ 个连续字节的数组。每个字节都有一个唯一的虚拟地址，作为到数组的索引。VM 系统将虚拟内存分割为虚拟页面（Virtual Page, VP），以虚拟页面作为传输单元，每个虚拟页面的大小为 $P=2^p$ 字节。同样地，物理内存被分割为多个物理页面（Physical Page, PP），物理页面的大小也为 $P$ 字节。
- 虚拟页面往往很大，通常是 4KB～2MB。
- 虚拟内存页面通常缓存在物理内存中。
  - 每个虚拟页面都可以放置在任何的物理页面中，不会有内存碎片

{{<figure width="600" src="/images/vm-as-a-tool-for-caching.jpg" caption="一个 VM 系统如何使用主存作为缓存的">}}

---

MMU（内存管理单元）中的地址翻译硬件在将一个虚拟地址转换为物理地址时，都会读取「页表（page table）」，页表是一种数据结构，它存放在物理内存中，包含了虚拟页面到物理页面的映射关系。页表由操作系统负责维护。

{{<figure width="600" src="/images/page-table.jpg" caption="页表">}}

页表是一个页表条目（Page Table Entry，PTE）的数组。虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个 PTE。
- PTE 由一个「有效位」和一个 $n$ 位地址字段组成。
- 有效位表明虚拟页面当前是否被缓存在主存中。
  - 如果设置了有效位（为 1），那么地址字段就表示物理内存中的物理页面的起始位置，这个物理页面中缓存了该虚拟页面。
  - 如果没有设置有效位（为 0），地址字段为空就表示这个虚拟页面还未被分配（比如，PTE 5)，否则，这个地址指向该虚拟页面在磁盘上的起始位置（比如，PTE 3、PTE 6）。

假设，每个虚拟页面的大小是 4K（$2^{12}$），虚拟地址的位数为 16 位，那么需要多少个页表条目呢？

计算：$2^n/2^p=2^{n-p}=2^{16-12}=16$，系统中总共有 16 个页面，其中每个页面都需要一个页表条目，所以需要 16 个 PTE。

---

在虚拟内存的习惯说法中，DRAM 缓存不命中称为「缺页（page fault）」。地址翻译硬件从页表中的页表条目的有效位推断出虚拟页面未被缓存时，就会触发一个缺页异常。缺页异常调用内核中的缺页异常处理程序，该程序会选择一个牺牲页面，如果被选中的牺牲页面已经被修改了，那么内核就会将它复制到磁盘，然后内核从磁盘复制请求的页面到内存中，并更新 PTE，随后返回。当异常处理程序返回时，它会重新执行导致缺页的指令，该指令会把导致缺页的虚拟地址重新发送到地址翻译硬件。

---

操作系统为每个进程提供了一个独立的页表，因而也就是每个进程都有一个独立的虚拟地址空间。

{{<figure width="600" src="/images/virtual-address-space-for-process.jpg" caption="VM 如何为进程提供独立的地址空间">}}

从图中还可以看到，多个虚拟页面可以映射到同一个共享到物理页面上。

VM 简化了链接和加载、代码和数据共享，以及应用程序的内存分配。
- 简化链接
  - 每个程序都有相似的虚拟地址空间，这使得代码、数据，以及堆始终从相同的地址开始。比如，对于 64 位地址空间，代码段总是从虚拟地址 0x400000 开始。数据段跟在代码段之后，中间是满足对齐要求的空白。栈在用户进程地址空间最高的部分，并向下生长。
- 简化加载
  - 要把目标文件中 .text 和 .data 段加载到一个新创建的进程中，Linux 加载器为代码和数据段分配虚拟页面，并创建标记为无效的 PTE。
  - 根据虚拟内存系统的要求，逐页复制 .text 和 .data 部分。
- 简化共享
  - 将不同地址空间中的虚拟页面映射到同一个物理页面（例如，图中的 PP 6）
- 简化内存分配
  - 在一个运行在用户进程中的程序需要额外的堆空间时（如调用 malloc），操作系统分配 $k$ 个连续的虚拟内存页面，并将它们映射到物理内存中任意位置的 $k$ 个任意的物理页面（不需要连续，可以随机分散）。

---

VM 实现可读、可写和可运行的内存访问控制。
- 扩展页表条目，增加一个权限位。
- MMU 在每次内存访问时检查这些权限位。
  - 如果一个指令违反了权限控制，那么 CPU 就触发一个异常。

{{<figure width="600" src="/images/page-level-memory-protection.jpg" caption="用虚拟内存来提供页面级的内存保护">}}

例如，进程 i 有读 VP 0，读和执行 VP1，读写 VP2 的权限。

## 地址翻译

形式上来说，地址翻译是一个 $N$ 元素的虚拟地址空间（VAS）中的元素和一个 $M$ 元素的物理地址空间（PAS）中元素之间的映射。

MMU 利用页表来实现这种映射。在 CPU 中有一个控制寄存器叫「页表基地址寄存器（Page Table Base Register，PTBR），它指向当前页表。$n$ 位的虚拟地址分成两个部分：一个 $p$ 位的虚拟页面偏移（Virtual Page Offset，VPO）和一个 ($n-p$) 位的虚拟页号（Virtual Page Number，VPN）。

{{<figure width="600" src="/images/address-translation.jpg" caption="使用页表的地址翻译">}}

MMU 利用 VPN 来选择适当的 PTE。例如，VPN 0 选择 PTE 0，VPN 1 选择 PTE 1，以此类推。将页表条目中「物理页号（Physical Page Number，PPN）和虚拟地址中的 VPO 串联起来，就得到相应的物理地址。由于物理和虚拟页面都是 $P$ 字节的，所以「物理页面偏移（Physical Page Offset，PPO）和 VPO 是相同的。


下图展示了页面命中时，CPU 硬件执行的步骤。

{{<figure width="600" src="/images/page-hit.jpg" caption="页命中">}}

1）CPU 生成一个虚拟地址，并把它发送给 MMU。2-3）MMU 生成 PTE 地址，并从高速缓存/主存中得到 PTE。4）MMU 构造物理地址，并把它传送给高速缓存/主存。5）高速缓存/主存将请求的数据传送给 CPU。

页面命中完全是由硬件来处理的，与之不同的是，处理缺页需要硬件和操作系统内核协作完成，如图：

{{<figure width="600" src="/images/page-fault.jpg" caption="缺页">}}

1）CPU 生成一个虚拟地址，并把它发送给 MMU。2-3）MMU 生成 PTE 地址，并从高速缓存/主存中得到 PTE。4）PTE 中的有效位为 0，因此 MMU 触发缺页异常。5）缺页处理程序确定出物理内存中的牺牲页，如果这个页面已经被修改，那么就把它换出（Page out）到磁盘。6）缺页处理程序调入（Page in）新的页面，并更新内存中的 PTE。7）缺页处理程序返回到原来的进程，再次指向导致缺页的指令。

### 利用 TLB 加速地址翻译

每次 CPU 产生一个虚拟地址，MMU 就要访问内存两次，一次是获取用于地址翻译的 PTE，再一次是实际的内存请求。即便 PTE 像其他存储器字一样缓存在高速缓存 L1 中，它们也可能会被其他数据引用逐出缓存，并且 L1 缓存中的命中仍然需要 1-3 个时钟周期。许多系统为消除这种开销，它们在 MMU 中包括了一个「翻译后备缓冲器（Translation Lookaside Buffer，TLB）」。

TLB 是一个小的、虚拟寻址的缓存，其中每一「行」都保存着一个由单个 PTE 组成的「块」。TLB 有高度的相联度。

{{<figure width="600" src="/images/TLB.jpg" caption="虚拟地址中用以访问 TLB 的组成部分">}}

虚拟地址中的 VPN 被拆分为两个部分：TLB 标记（TLBT）和 TLB 索引（TLBI）。分别用于缓存的组选择和行匹配。如果 TLB 有 $T=2^t$ 个组，那么 TLB 索引是由 VPN 的 $t$ 个最低位组成的，而 TLB 标记是由 VPN 中剩余的位组成的。

{{<figure src="/images/tlb-hit-and-miss.jpg" caption="TLB 命中和不命中的操作图">}}

从上图可以看到，在 TLB 命中时，它消除了一次内存访问（步骤2和步骤3，MMU 从 TLB中取出相应的 PTE）。当 TLB 不命中时，会导致额外的内存访问（MMU 必须从 L1 缓存中取出相应的 PTE，并存放在 TLB 中）。幸运的是，TLB 不命中很少发生。




